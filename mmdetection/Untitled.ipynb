{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19c1942-4fbe-4e56-b3aa-565730505ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "sys.path.append(\"/home/a4000/huyenhc/mmdetection/\")\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import (collect_env, get_root_logger, setup_multi_processes,\n",
    "                         update_data_root)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train a detector')\n",
    "    parser.add_argument('--config', default = 'configs/swin/config_swinT.py', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--auto-resume',\n",
    "        action='store_true',\n",
    "        help='resume from the latest checkpoint automatically')\n",
    "    parser.add_argument(\n",
    "        '--no-validate',\n",
    "        action='store_true',\n",
    "        help='whether not to evaluate the checkpoint during training')\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='(Deprecated, please use --gpu-id) number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='(Deprecated, please use --gpu-id) ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-id',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help='id of gpu to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--diff-seed',\n",
    "        action='store_true',\n",
    "        help='Whether or not set different seeds for different ranks')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file (deprecate), '\n",
    "        'change to --cfg-options instead.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. If the value to '\n",
    "        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n",
    "        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n",
    "        'Note that the quotation marks are necessary and that no white space '\n",
    "        'is allowed.')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    args = parser.parse_args()\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    if args.options and args.cfg_options:\n",
    "        raise ValueError(\n",
    "            '--options and --cfg-options cannot be both '\n",
    "            'specified, --options is deprecated in favor of --cfg-options')\n",
    "    if args.options:\n",
    "        warnings.warn('--options is deprecated in favor of --cfg-options')\n",
    "        args.cfg_options = args.options\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f87be4-7d55-4f33-9ea4-07b774bfff59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a4000/huyenhc/mmdetection/mmdet/utils/setup_env.py:32: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/home/a4000/huyenhc/mmdetection/mmdet/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "2022-05-04 05:44:48,216 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA RTX A4000\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.4.r11.4/compiler.30033411_0\n",
      "GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "PyTorch: 1.10.1\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.11.2\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.3.17\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 11.3\n",
      "MMDetection: 2.23.0+c72bc70\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-05-04 05:44:50,706 - mmdet - INFO - Distributed training: False\n",
      "2022-05-04 05:44:53,177 - mmdet - INFO - Config:\n",
      "model = dict(\n",
      "    type='MaskRCNN',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        embed_dims=96,\n",
      "        depths=[2, 2, 6, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        window_size=7,\n",
      "        mlp_ratio=4,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.2,\n",
      "        patch_norm=True,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        with_cp=False,\n",
      "        convert_weights=True,\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'\n",
      "        )),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[96, 192, 384, 768],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=32,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=32,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='AutoAugment',\n",
      "        policies=[[{\n",
      "            'type':\n",
      "            'Resize',\n",
      "            'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333),\n",
      "                          (608, 1333), (640, 1333), (672, 1333), (704, 1333),\n",
      "                          (736, 1333), (768, 1333), (800, 1333)],\n",
      "            'multiscale_mode':\n",
      "            'value',\n",
      "            'keep_ratio':\n",
      "            True\n",
      "        }],\n",
      "                  [{\n",
      "                      'type': 'Resize',\n",
      "                      'img_scale': [(400, 1333), (500, 1333), (600, 1333)],\n",
      "                      'multiscale_mode': 'value',\n",
      "                      'keep_ratio': True\n",
      "                  }, {\n",
      "                      'type': 'RandomCrop',\n",
      "                      'crop_type': 'absolute_range',\n",
      "                      'crop_size': (384, 600),\n",
      "                      'allow_negative_crop': True\n",
      "                  }, {\n",
      "                      'type':\n",
      "                      'Resize',\n",
      "                      'img_scale': [(480, 1333), (512, 1333), (544, 1333),\n",
      "                                    (576, 1333), (608, 1333), (640, 1333),\n",
      "                                    (672, 1333), (704, 1333), (736, 1333),\n",
      "                                    (768, 1333), (800, 1333)],\n",
      "                      'multiscale_mode':\n",
      "                      'value',\n",
      "                      'override':\n",
      "                      True,\n",
      "                      'keep_ratio':\n",
      "                      True\n",
      "                  }]]),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "classes = ('Nóc xe ', 'Pa vô lê', 'Kính chắn gió trước', 'Ca pô trước',\n",
      "           'Ca Lăng', 'Ba đờ sốc trước', 'Lô gô', 'Cốp sau', 'Ba đờ sốc sau',\n",
      "           'Kính chắn gió sau', 'Đèn gầm', 'Cụm đèn trước', 'Đèn cửa',\n",
      "           'Cụm kính chiếu hậu', 'Kính cánh cửa', 'Kính chết góc cửa',\n",
      "           'Cánh cửa', 'Cụm đèn hậu', 'Đèn lùi', 'Kính hông', 'Hông vè sau xe',\n",
      "           'Trụ kính sau', 'Trụ kính trước', 'Đèn xi nhan ba đờ sốc',\n",
      "           'Đèn phản quang', 'Vè trước xe', 'Nẹp ca lăng', 'Viền nóc xe',\n",
      "           'Móp (bẹp)', 'Nứt (rạn)', 'Vỡ, Thủng, Rách', 'Trầy (xước)')\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/home/a4000/huyenhc/Swin-Transformer-Object-Detection/dataset/train.json',\n",
      "        classes=('Nóc xe ', 'Pa vô lê', 'Kính chắn gió trước', 'Ca pô trước',\n",
      "                 'Ca Lăng', 'Ba đờ sốc trước', 'Lô gô', 'Cốp sau',\n",
      "                 'Ba đờ sốc sau', 'Kính chắn gió sau', 'Đèn gầm',\n",
      "                 'Cụm đèn trước', 'Đèn cửa', 'Cụm kính chiếu hậu',\n",
      "                 'Kính cánh cửa', 'Kính chết góc cửa', 'Cánh cửa',\n",
      "                 'Cụm đèn hậu', 'Đèn lùi', 'Kính hông', 'Hông vè sau xe',\n",
      "                 'Trụ kính sau', 'Trụ kính trước', 'Đèn xi nhan ba đờ sốc',\n",
      "                 'Đèn phản quang', 'Vè trước xe', 'Nẹp ca lăng', 'Viền nóc xe',\n",
      "                 'Móp (bẹp)', 'Nứt (rạn)', 'Vỡ, Thủng, Rách', 'Trầy (xước)'),\n",
      "        img_prefix='dataset/img',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='AutoAugment',\n",
      "                policies=[[{\n",
      "                    'type':\n",
      "                    'Resize',\n",
      "                    'img_scale': [(480, 1333), (512, 1333), (544, 1333),\n",
      "                                  (576, 1333), (608, 1333), (640, 1333),\n",
      "                                  (672, 1333), (704, 1333), (736, 1333),\n",
      "                                  (768, 1333), (800, 1333)],\n",
      "                    'multiscale_mode':\n",
      "                    'value',\n",
      "                    'keep_ratio':\n",
      "                    True\n",
      "                }],\n",
      "                          [{\n",
      "                              'type': 'Resize',\n",
      "                              'img_scale': [(400, 1333), (500, 1333),\n",
      "                                            (600, 1333)],\n",
      "                              'multiscale_mode': 'value',\n",
      "                              'keep_ratio': True\n",
      "                          }, {\n",
      "                              'type': 'RandomCrop',\n",
      "                              'crop_type': 'absolute_range',\n",
      "                              'crop_size': (384, 600),\n",
      "                              'allow_negative_crop': True\n",
      "                          }, {\n",
      "                              'type':\n",
      "                              'Resize',\n",
      "                              'img_scale': [(480, 1333), (512, 1333),\n",
      "                                            (544, 1333), (576, 1333),\n",
      "                                            (608, 1333), (640, 1333),\n",
      "                                            (672, 1333), (704, 1333),\n",
      "                                            (736, 1333), (768, 1333),\n",
      "                                            (800, 1333)],\n",
      "                              'multiscale_mode':\n",
      "                              'value',\n",
      "                              'override':\n",
      "                              True,\n",
      "                              'keep_ratio':\n",
      "                              True\n",
      "                          }]]),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/home/a4000/huyenhc/Swin-Transformer-Object-Detection/dataset/validation.json',\n",
      "        img_prefix='dataset/img',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('Nóc xe ', 'Pa vô lê', 'Kính chắn gió trước', 'Ca pô trước',\n",
      "                 'Ca Lăng', 'Ba đờ sốc trước', 'Lô gô', 'Cốp sau',\n",
      "                 'Ba đờ sốc sau', 'Kính chắn gió sau', 'Đèn gầm',\n",
      "                 'Cụm đèn trước', 'Đèn cửa', 'Cụm kính chiếu hậu',\n",
      "                 'Kính cánh cửa', 'Kính chết góc cửa', 'Cánh cửa',\n",
      "                 'Cụm đèn hậu', 'Đèn lùi', 'Kính hông', 'Hông vè sau xe',\n",
      "                 'Trụ kính sau', 'Trụ kính trước', 'Đèn xi nhan ba đờ sốc',\n",
      "                 'Đèn phản quang', 'Vè trước xe', 'Nẹp ca lăng', 'Viền nóc xe',\n",
      "                 'Móp (bẹp)', 'Nứt (rạn)', 'Vỡ, Thủng, Rách', 'Trầy (xước)')),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file=\n",
      "        '/home/a4000/huyenhc/Swin-Transformer-Object-Detection/dataset/test.json',\n",
      "        img_prefix='dataset/img',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('Nóc xe ', 'Pa vô lê', 'Kính chắn gió trước', 'Ca pô trước',\n",
      "                 'Ca Lăng', 'Ba đờ sốc trước', 'Lô gô', 'Cốp sau',\n",
      "                 'Ba đờ sốc sau', 'Kính chắn gió sau', 'Đèn gầm',\n",
      "                 'Cụm đèn trước', 'Đèn cửa', 'Cụm kính chiếu hậu',\n",
      "                 'Kính cánh cửa', 'Kính chết góc cửa', 'Cánh cửa',\n",
      "                 'Cụm đèn hậu', 'Đèn lùi', 'Kính hông', 'Hông vè sau xe',\n",
      "                 'Trụ kính sau', 'Trụ kính trước', 'Đèn xi nhan ba đờ sốc',\n",
      "                 'Đèn phản quang', 'Vè trước xe', 'Nẹp ca lăng', 'Viền nóc xe',\n",
      "                 'Móp (bẹp)', 'Nứt (rạn)', 'Vỡ, Thủng, Rách', 'Trầy (xước)')))\n",
      "evaluation = dict(metric=['bbox', 'segm'])\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.0001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.05,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1000,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[27, 33])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=36)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'\n",
      "work_dir = '/media/a4000/Data Center/huyenhc/mmdetection/work_dirs/config_swinT'\n",
      "auto_resume = False\n",
      "gpu_ids = [0]\n",
      "\n",
      "2022-05-04 05:44:53,178 - mmdet - INFO - Set random seed to 223867746, deterministic: False\n",
      "2022-05-04 05:44:53,408 - mmdet - INFO - load checkpoint from http path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\n",
      "2022-05-04 05:44:53,484 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-05-04 05:44:53,496 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2022-05-04 05:44:53,499 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a4000/huyenhc/mmdetection/mmdet/datasets/api_wrappers/coco_api.py:20: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by \"pip install pycocotools\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = parse_args()\n",
    "\n",
    "cfg = Config.fromfile(args.config)\n",
    "\n",
    "# update data root according to MMDET_DATASETS\n",
    "update_data_root(cfg)\n",
    "\n",
    "if args.cfg_options is not None:\n",
    "    cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# set multi-process settings\n",
    "setup_multi_processes(cfg)\n",
    "\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# work_dir is determined in this priority: CLI > segment in file > filename\n",
    "if args.work_dir is not None:\n",
    "    # update configs according to CLI args if args.work_dir is not None\n",
    "    cfg.work_dir = args.work_dir\n",
    "elif cfg.get('work_dir', None) is None:\n",
    "    # use config filename as default work_dir if cfg.work_dir is None\n",
    "    cfg.work_dir = osp.join('/media/a4000/Data Center/huyenhc/mmdetection/work_dirs',\n",
    "                            osp.splitext(osp.basename(args.config))[0])\n",
    "if args.resume_from is not None:\n",
    "    cfg.resume_from = args.resume_from\n",
    "cfg.auto_resume = args.auto_resume\n",
    "if args.gpus is not None:\n",
    "    cfg.gpu_ids = range(1)\n",
    "    warnings.warn('`--gpus` is deprecated because we only support '\n",
    "                  'single GPU mode in non-distributed training. '\n",
    "                  'Use `gpus=1` now.')\n",
    "if args.gpu_ids is not None:\n",
    "    cfg.gpu_ids = args.gpu_ids[0:1]\n",
    "    warnings.warn('`--gpu-ids` is deprecated, please use `--gpu-id`. '\n",
    "                  'Because we only support single GPU mode in '\n",
    "                  'non-distributed training. Use the first GPU '\n",
    "                  'in `gpu_ids` now.')\n",
    "if args.gpus is None and args.gpu_ids is None:\n",
    "    cfg.gpu_ids = [args.gpu_id]\n",
    "\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "if args.launcher == 'none':\n",
    "    distributed = False\n",
    "else:\n",
    "    distributed = True\n",
    "    init_dist(args.launcher, **cfg.dist_params)\n",
    "    # re-set gpu_ids with distributed training mode\n",
    "    _, world_size = get_dist_info()\n",
    "    cfg.gpu_ids = range(world_size)\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "# init the logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "meta['config'] = cfg.pretty_text\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "# set random seeds\n",
    "seed = init_random_seed(args.seed)\n",
    "seed = seed + dist.get_rank() if args.diff_seed else seed\n",
    "logger.info(f'Set random seed to {seed}, '\n",
    "            f'deterministic: {args.deterministic}')\n",
    "set_random_seed(seed, deterministic=args.deterministic)\n",
    "cfg.seed = seed\n",
    "meta['seed'] = seed\n",
    "meta['exp_name'] = osp.basename(args.config)\n",
    "\n",
    "model = build_detector(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "# if len(cfg.workflow) == 2:\n",
    "#     val_dataset = copy.deepcopy(cfg.data.val)\n",
    "#     val_dataset.pipeline = cfg.data.train.pipeline\n",
    "#     datasets.append(build_dataset(val_dataset))\n",
    "# if cfg.checkpoint_config is not None:\n",
    "#     # save mmdet version, config file content and class names in\n",
    "#     # checkpoints as meta data\n",
    "#     cfg.checkpoint_config.meta = dict(\n",
    "#         mmdet_version=__version__ + get_git_hash()[:7],\n",
    "#         CLASSES=datasets[0].CLASSES)\n",
    "# # add an attribute for visualization convenience\n",
    "# model.CLASSES = datasets[0].CLASSES\n",
    "# train_detector(\n",
    "#     model,\n",
    "#     datasets,\n",
    "#     cfg,\n",
    "#     distributed=distributed,\n",
    "#     validate=(not args.no_validate),\n",
    "#     timestamp=timestamp,\n",
    "#     meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8359d0-6673-401c-84d3-4b5e827a8090",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_metas': DataContainer({'filename': 'dataset/img/image1641258700158906_2022012600015_THVO_TRUOC_ba_d_xoc_truoc.jpg', 'ori_filename': 'image1641258700158906_2022012600015_THVO_TRUOC_ba_d_xoc_truoc.jpg', 'ori_shape': (1200, 1600, 3), 'img_shape': (704, 939, 3), 'pad_shape': (704, 960, 3), 'scale_factor': array([0.586875  , 0.58666664, 0.586875  , 0.58666664], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([123.675, 116.28 , 103.53 ], dtype=float32), 'std': array([58.395, 57.12 , 57.375], dtype=float32), 'to_rgb': True}}),\n",
       " 'img': DataContainer(tensor([[[-1.2274, -1.4158, -1.3815,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.3130, -1.3130, -1.3815,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.2788, -1.2617, -1.3302,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 1.5125,  1.4954,  1.4098,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4783,  1.4783,  1.4269,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4440,  1.4612,  1.4440,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-1.1254, -1.3179, -1.2829,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.2129, -1.2129, -1.2829,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.1779, -1.1604, -1.2304,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 1.5007,  1.4832,  1.4132,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4657,  1.4657,  1.4132,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.3957,  1.4132,  1.4132,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.9330, -1.1247, -1.0898,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.0027, -1.0201, -1.0898,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-0.9853, -0.9853, -1.0376,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 1.6988,  1.6814,  1.6117,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.6640,  1.6640,  1.6117,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.6117,  1.6291,  1.6291,  ...,  0.0000,  0.0000,  0.0000]]])),\n",
       " 'gt_bboxes': DataContainer(tensor([[371.8029, 298.9008, 928.1546, 636.4570],\n",
       "         [214.4676, 262.2165, 226.2110, 267.3792],\n",
       "         [260.1324,  78.9888, 620.0276, 120.0731],\n",
       "         [330.3754, 372.5920, 413.8408, 488.3413],\n",
       "         [287.5923, 365.9568, 304.7877, 401.1099],\n",
       "         [382.9712, 103.3355, 787.0347, 229.6389],\n",
       "         [520.5347, 175.3664, 909.8793, 459.4245],\n",
       "         [431.7053, 290.5114, 777.3923, 394.4981],\n",
       "         [892.1087, 226.0896, 911.9099, 278.3381],\n",
       "         [842.3652, 250.9467, 869.2676, 281.3829],\n",
       "         [186.0922, 216.9904, 358.0583, 435.0779],\n",
       "         [108.0789, 208.6069, 213.3526, 392.7205],\n",
       "         [132.8802, 334.4293, 273.1668, 448.8117],\n",
       "         [ 74.2338, 212.5141, 135.8322, 342.2672],\n",
       "         [608.1903, 573.8069, 735.0962, 611.6293],\n",
       "         [347.2305, 127.7467, 519.5076, 233.0885],\n",
       "         [273.0495, 227.5445, 556.8915, 481.1898],\n",
       "         [200.7876, 107.1723, 378.0766, 234.1269],\n",
       "         [ 72.2091, 157.2560, 139.9697, 213.9573],\n",
       "         [188.7331, 235.8635, 228.4528, 366.7371],\n",
       "         [129.5703, 107.8000, 240.1845, 216.7909],\n",
       "         [158.0983,  89.6427, 385.0018, 146.9600]])),\n",
       " 'gt_labels': DataContainer(tensor([ 8, 31,  0, 31, 31,  9,  7, 17, 17,  6, 16, 16,  1, 25, 24, 21, 20, 14,\n",
       "         13, 28, 14, 27])),\n",
       " 'gt_masks': DataContainer(BitmapMasks(num_masks=22, height=704, width=960))}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ccf68-f6dc-4815-8aeb-441f1c7ff83b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
